{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of compressor_train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abel-bernabeu/facecompressor/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myODRbvAf3EK",
        "colab_type": "text"
      },
      "source": [
        "# Compression models training\n",
        "\n",
        "This notebook is provided for anyone to use it as a scripted recipe for training the models from the autoencoder.models package. The notebook can also be read as a journal of the trial an error process that lead to the best known pre-trained model.\n",
        "\n",
        "The notebook is divided in sections, each of them corresponding to an experiment. In each of those experiments we craft an incrementally functional prototype or we test a different idea. A series of seven experiments leads to the final model.\n",
        "\n",
        "For each experiment we do:\n",
        "\n",
        "- Specify the hyperparmeters (hparams).\n",
        "- Instantiate a model from the autoencoder.models package.\n",
        "- Create dataloaders with the input patch size and batch size especified in hparams.\n",
        "- Embed a TensorBoard for visualiazing the training.\n",
        "- Kick a training session lasting until the number of epochs especified in hparams is reached.\n",
        "- Summarize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiB2DKaId1qC",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Firstly, we download from DropBox the dataset and the models source code if needed.\n",
        "\n",
        "Optionally, when the download_trained_models Bool is set to True in the next code cell, the notebook also downloads all the pre-trained weights and the TensorBoard logs. Setting this option to True is useful if you only intend to browse the TensorBoard instances from Google Collab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO6AfnaUoiI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_trained_models = True\n",
        "\n",
        "# When on Google Colab force PyTorch version to 1.4.0 (for compatibility of the .pt files)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    !pip install torch==1.4.0 torchvision==0.5.0\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Get the dataset if needed\n",
        "import os.path\n",
        "if not os.path.isdir('./data'):\n",
        "    !rm -rf image_dataset.zip\n",
        "    !wget https://www.dropbox.com/s/n03i55xxwqnned4/image_dataset.zip && \\\n",
        "    unzip -q image_dataset.zip && rm image_dataset.zip\n",
        "    !wget https://www.dropbox.com/s/ds815v4i8a8vyep/ginger.tgz && \\\n",
        "    tar xzf ginger.tgz && rm ginger.tgz\n",
        "\n",
        "# Get the latest source code if needed\n",
        "if not os.path.isdir('./autoencoder'):\n",
        "    !wget https://www.dropbox.com/s/at2d0nmmiw118ap/facecompressor-master.zip && \\\n",
        "    unzip -q facecompressor-master.zip && rm facecompressor-master.zip && \\\n",
        "    mv facecompressor-master/autoencoder/ . && \\\n",
        "    rm facecompressor-master -rf\n",
        "\n",
        "if not os.path.isdir('./share') and download_trained_models:\n",
        "    # The fallback for when not in Collab is to download share from Dropbox\n",
        "    !wget https://www.dropbox.com/s/76w9gsga8mz5ve4/share.tgz && tar xzf share.tgz && rm share.tgz\n",
        "    !wget https://www.dropbox.com/s/xd9noc1tbfd173o/experiment5.tgz && tar xzf experiment5.tgz && rm experiment5.tgz\n",
        "    !wget https://www.dropbox.com/s/zt2hrac0dslzyy9/experiment6.tgz && tar xzf experiment6.tgz && rm experiment6.tgz\n",
        "    !wget https://www.dropbox.com/s/anfb3jrk72fta6y/experiment7.tgz && tar xzf experiment7.tgz && rm experiment7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAJ1smCz1y0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autoencoder.models\n",
        "import autoencoder.utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGvOW4eo2S7Y",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 1: sparsity at 1/2\n",
        "\n",
        "Our baseline model effort focuses on training the neural network proposed in \"Lossy image compression with compression autoencoders\", by Lucas Theis, Wenzhe Shi, Andrew Cunningham & Ferenc Husz, published in 2017 (see the [original paper](https://arxiv.org/pdf/1703.00395v1.pdf) for details). We make the addition of batch normalization layers for improved robustness, but other than that we try to stick to the proposed model as much as possible.\n",
        "\n",
        "The purpose of this experiment is to confirm that we have understood the architecture, and confirm that we can extract features and use them for reconstructing the original image.\n",
        "\n",
        "The paper authors claim that their \"subpixel\" operator is a better upsampler than transposed convolution, because it does not suffer from the checker board artifact produced by the kernel overlaps (see [this blog post](https://distill.pub/2016/deconv-checkerboard/) for illustrated examples). This a bold clain that needs, at least, a visual confirmation.\n",
        "\n",
        "For this first experiment we will not implement any kind of quantization and we will only perform a 50% dimensionality reduction (sparsity from now). This dimensionality reduction is achieved by using 96 channels in the features tensor (as opposed to 192 channels that would be needed if we wanted to keep the dimensionality from the input)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvnxFWQlPiY",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdAi7hZDf3EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 32,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 128,\n",
        "    'block_height' : 128,\n",
        "    'hidden_state_num_channels' : 96,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 5000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 12577,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment1\",\n",
        "    'port' : 6100,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntf1Z4_Yf3Eg",
        "colab_type": "text"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OKn6N3TbJ84",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c5HCzjKMrL6g"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4A-S3GBUrL6k",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysBd-c-DlYA8",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKr9CMXqSDj2",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cyzSi8YlnvG",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jOW0NNlhfHA5",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RipuvzhxizA7",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "We see there is no bluriness, which is very pleasant to see. The subpixel operator certainly delivers a sharp reconstruction.\n",
        "\n",
        "The quality of this model sets 43 db as upper bound on the accuracy for this model. The quality meassurmentt will not get any better as we try smaller sparsity ratios in the next experiments\n",
        "\n",
        "Training the model took 4 days on a Tesla P100, setting also a lower bound on how long will take us to train state of de art models for image compression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UynFM6TYEL12",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 2: sparsity at 1/4\n",
        "\n",
        "In this second experiment we further squeeze the features tensor, going from 96 channels to only 48 for achieving a 25% dimensionality reduction to confirm the images can be further squeezed without serious damage. We define a serious damage a PSNR for the test set below 32 db.\n",
        "\n",
        "Again no quantization is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJEvb7N22tNR",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xBTpKybm2yAp",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 48,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 16000,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment2\",\n",
        "    'port' : 6200,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aE-Rr3v2pdD",
        "colab_type": "text"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW_nmDLzGj0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xpJojH_grVTD"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mtTm5hxPrVTP",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxmt1Lv4wBl",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxUAGmi43tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deyZjDZx5jfa",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCm6ZWG05exL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8rcUyNm2kW4w"
      },
      "source": [
        "## Results\n",
        "\n",
        "We see training reaching a 32 dB PSNR for the test set in just 31 hours of training, with the slope suggesting the quality is far from estagnated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRgc18irGJDk"
      },
      "source": [
        "#  Experiment 3: 3 bits quantization\n",
        "\n",
        "On this third experiment we introduce 3 bits quantization of the features. This experiment is intended to empirically prove the suitability of a novel concept for training a quantizing model, which we call **training in two stages**:\n",
        "\n",
        "1. A quantizing model is trained with the quantization and dequantization modules being bypassed.\n",
        "\n",
        "2. The quantizing model in trained with the encoder weights frozen and the quantization and dequantization modules enabled, with the purpose of training the decoder for undoing the quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BvXFvg6JGJEC"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MmoCLvQAGJEG",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 48,\n",
        "    'quantize' : True,\n",
        "    'num_bits' : 3,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 2500,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment3\",\n",
        "    'port' : 6300,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p  share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AFNQeJguGJEV"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OMSkESehGJEY",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wsde2q-qrdt4"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-NLmRyGrduH",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sLqPM4SVGJEo"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3__3I_RGJEq",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7a4-8S2zGJE1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8fTNoEnPGJE3",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLrVXJvjry-e",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "The test PSNR improves about 0.2 dB, showing that the decoder can learn to undo some of the noise introduced by the quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rtCg0G_xXOcg"
      },
      "source": [
        "# Experiment 4: sparsity at 1/8\n",
        "\n",
        "At this point it becomes evident that if we want to achieve a compression ratio in the range of 1/10 to 1/20 for comparing with JPEG and JPEG 2000, it is unlikely that using a 1/4 sparsity is bringing us even nearly close, no matter what the PSNR the image codec is.\n",
        "\n",
        "Although we can certainly try to rely on quantization and entropic coding for bridging the compression ratio gap from 1/4 to 1/10, it seems a bit of a stretch to say the least. Achiving a sparsity of 1/8 on the autoencoder would be a better starting point for the quantization and entropy coding effort to bridge the gap with JPEG. \n",
        "\n",
        "Hence, in this experiment we train a model that reduces dimensionality to 1/8, although but we do not yet perform  quantization. We do not introduce quantization yet because we learned in experiment 3 that it is possible to first train without quantization and then introduce the quantization on a second stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mmSbHULXXOdB"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKJiya2UXOdG",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 110000,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment4\",\n",
        "    'port' : 6400,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b91bYEFdXOdV"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uSDuBz5_XOdX",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U5ScHvWZrkIW"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aG-duT5yrkIZ",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gbgz7eK1XOde"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yXPwaOcCXOdf",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MeAjZle3XOdp"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8K4Tt9ddXOdq",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RROjNfqQ07RG"
      },
      "source": [
        "## Results\n",
        "\n",
        "The test PSNR is 40.1 dB, but could only achieve this result at the expense of training for 14 days on an Tesla P100 (with a approximated cost of 350 euros in Google Cloud Platform)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NcJQhhMHX8cE"
      },
      "source": [
        "#  Experiment 5: 6 bits quantization\n",
        "\n",
        "We do the second stage of training the quantizing model, expecting to confirme once again that the training in two stages helps to reduce the amount of noise introduced by the quantization.\n",
        "\n",
        "Similarly to what it was done for experiment 3, the second stage of the training is achieved is by transfering the encoder and decoder weights learned with experiment 4, freezing the encoder weights and further training the decoder for undoing the quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K7BbLuRjX8cP"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFgpRLGhX8cX",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-8,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : True,\n",
        "    'num_bits' : 6,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 12650,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment5\",\n",
        "    'port' : 6500,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mDGfpbPiX8cy"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CCmRZr9X8c8",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9PUc0fErgR8"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n2KXO_gprgSL",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HpFrINjjX8dB"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6_0YSBKWX8dC",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6-mgwrlMX8dN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vV5cwb9NX8dP",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNmolbjX3cD8",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "Adding the quantization worsened the test PSNR: went from 40.1 dB to 39.7 dB. However, by further training the decoder we improved the test PSNR from 39.7 dB to 39.9 dB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n4BQD-rSPtrL"
      },
      "source": [
        "# Experiment 6: blending in more training data\n",
        "\n",
        "In this experiment we try a radically different approach for training the same model from experiment 4. Rather than running for as many epochs as possible (110K in experiment 4) we do fewer epochs with an increased dataset size (60K samples as opposed to 1K samples in experiment 4) and an increased learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z4YU_26MPtrW"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0M7rmdf6Ptrc",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 2e-5,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 60000,\n",
        "    'test_dataset_size' : 6000,\n",
        "    'num_epochs' : 960,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment6\",\n",
        "    'port' : 6600,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2bUq86RIPtrv"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YkCJsNRGPtrx",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iJR_u2U4Ptr8"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RF9iqNx6Ptr_",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "plzEo7qtPtsE"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUFtgJysPtsF",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QYGh1MhUPtsK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZ3Vph2JPtsL",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v8Ldi6fy3oA3"
      },
      "source": [
        "## Results\n",
        "\n",
        "The approach really pays off, achieving higher accuracy with just 5 days of training (a opposed to 14 days in experiment 4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s3Wj1F3ERlnw"
      },
      "source": [
        "#  Experiment 7: 6 bits quantization of final model\n",
        "\n",
        "In this  experiment we introduce a 6 bits quantization in the model from experiment 6. For the training we used only 12 additional hours of a Tesla P100.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XQnd9TbYRln6"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tLfBVbWbRloC",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-8,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : True,\n",
        "    'num_bits' : 6,\n",
        "    'train_dataset_size' : 60000,\n",
        "    'test_dataset_size' : 6000,\n",
        "    'num_epochs' : 350,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment7\",\n",
        "    'port' : 6700,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VUUR48_LRloZ"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IQcS602ORlob",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1tnAufY3Rlol"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MMM-WijJRlol",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8oe81ftRRloq"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mMnXZ-fRlor",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "munl0wimRlox"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y-8Ao0iURloy",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBLljsl07tve",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "A 6 bits quantization needed for increasing the compression ratio to 10.66 was introduced, which impacted the PSNR (going from 44.02 to 43.08 dB). Then the decoder was trained for removing that noise and went from 43.08 dB to 43.4 dB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nds4uNnRSvn",
        "colab_type": "text"
      },
      "source": [
        "# Final results\n",
        "\n",
        "The model from experiment 7 achieves a 10.6 compression ratio with a 43.4 dB PSNR, being the best choice so far."
      ]
    }
  ]
}