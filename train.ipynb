{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of compressor_train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abel-bernabeu/facecompressor/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myODRbvAf3EK",
        "colab_type": "text"
      },
      "source": [
        "# Compression models training\n",
        "\n",
        "This notebook is provided for third parties to be able to reproduce the training the compression models from the autoencoder.models package. The notebook can also be read as a journal of the trial an error process that lead to the final model.\n",
        "\n",
        "The notebook is divided in sections, each of them corresponding to an experiment. In each of those experiments we craft an incrementally functional prototype or we test a different idea. A series of seven experiments leads to the final model.\n",
        "\n",
        "For each experiment we do:\n",
        "\n",
        "- Specify the hyperparmeters (hparams).\n",
        "- Instantiate a model from the autoencoder.models package.\n",
        "- Create dataloaders with the input patch size and batch size especified in hparams.\n",
        "- Embed a TensorBoard for visualiazing the training.\n",
        "- Kick a training session lasting until the number of epochs especified in hparams is reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiB2DKaId1qC",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Firstly, we download from DropBox the dataset and the models source code if needed.\n",
        "\n",
        "Optionally, if only the download_trained_models Bool is set to True in the next code cell, the notebook also downloads all the pre-trained weights. Setting this option to True is useful if you only intend to browse the TensorBoard instances from Google Collab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO6AfnaUoiI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_trained_models = True\n",
        "\n",
        "# When on Google Colab force PyTorch version to 1.4.0 (for compatibility of the .pt files)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    !pip install torch==1.4.0 torchvision==0.5.0\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Get the dataset if needed\n",
        "import os.path\n",
        "if not os.path.isdir('./data'):\n",
        "    !rm -rf image_dataset.zip\n",
        "    !wget https://www.dropbox.com/s/n03i55xxwqnned4/image_dataset.zip && \\\n",
        "    unzip -q image_dataset.zip && rm image_dataset.zip\n",
        "    !wget https://www.dropbox.com/s/ds815v4i8a8vyep/ginger.tgz && \\\n",
        "    tar xzf ginger.tgz && rm ginger.tgz\n",
        "\n",
        "# Get the latest source code if needed\n",
        "if not os.path.isdir('./autoencoder'):\n",
        "    !wget https://www.dropbox.com/s/at2d0nmmiw118ap/facecompressor-master.zip && \\\n",
        "    unzip -q facecompressor-master.zip && rm facecompressor-master.zip && \\\n",
        "    mv facecompressor-master/autoencoder/ . && \\\n",
        "    rm facecompressor-master -rf\n",
        "\n",
        "if not os.path.isdir('./share') and download_trained_models:\n",
        "    # The fallback for when not in Collab is to download share from Dropbox\n",
        "    !wget https://www.dropbox.com/s/76w9gsga8mz5ve4/share.tgz && tar xzf share.tgz && rm share.tgz\n",
        "    !wget https://www.dropbox.com/s/xd9noc1tbfd173o/experiment5.tgz && tar xzf experiment5.tgz && rm experiment5.tgz\n",
        "    !wget https://www.dropbox.com/s/zt2hrac0dslzyy9/experiment6.tgz && tar xzf experiment6.tgz && rm experiment6.tgz\n",
        "    !wget https://www.dropbox.com/s/anfb3jrk72fta6y/experiment7.tgz && tar xzf experiment7.tgz && rm experiment7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAJ1smCz1y0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autoencoder.models\n",
        "import autoencoder.utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGvOW4eo2S7Y",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 1: sparsity at 1/2\n",
        "Our baseline model effort focuses on training the proposed neural network with the maximum possible accuracy, but not investing any effort in quantization of the features.\n",
        "\n",
        "This model assumes the input is provided in single-precision float values (using 32 bits per pixel color component) and provides a 50% dimensionality reduction of the input (or 1/2 sparsity). The dimensionality reduction is achieved by using 96 channels in the features tensor (as opposed to 192 channels that would be needed if we wanted to keep the dimensionality from the input).\n",
        "\n",
        "The purpose of this first experiment is to:\n",
        "\n",
        "- empirically prove that the input can be reconstructed accurately with the kind of neural network that is proposed in the paper.\n",
        "\n",
        "- set an upper bound on accuracy (which turned out be **43 db**)\n",
        "\n",
        "- somehow give an estimation of how long it takes to train a state of the art compression model (which turned out to take **4 days on a Tesla P100**)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvnxFWQlPiY",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdAi7hZDf3EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 32,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 128,\n",
        "    'block_height' : 128,\n",
        "    'hidden_state_num_channels' : 96,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 5000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 12577,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment1\",\n",
        "    'port' : 6100,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntf1Z4_Yf3Eg",
        "colab_type": "text"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OKn6N3TbJ84",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c5HCzjKMrL6g"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4A-S3GBUrL6k",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysBd-c-DlYA8",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKr9CMXqSDj2",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cyzSi8YlnvG",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jOW0NNlhfHA5",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UynFM6TYEL12",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 2: sparsity at 1/4\n",
        "\n",
        "In this second experiment we further squeeze the features tensor, going from 96 channels to only 48, for achieving a 25% dimensionality reduction. Again no quantization is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJEvb7N22tNR",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xBTpKybm2yAp",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 48,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 16000,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment2\",\n",
        "    'port' : 6200,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aE-Rr3v2pdD",
        "colab_type": "text"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW_nmDLzGj0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xpJojH_grVTD"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mtTm5hxPrVTP",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxmt1Lv4wBl",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxUAGmi43tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deyZjDZx5jfa",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCm6ZWG05exL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRgc18irGJDk"
      },
      "source": [
        "#  Experiment 3: 3 bits quantization\n",
        "\n",
        "On this third experiment we introduce 3 bits quantization of the features. This experiment shows the suitability of a novel concept for training a quantizing model, which we call **training in two stages**:\n",
        "\n",
        "1. A quantizing model is trained with the quantization and dequantization modules being bypassed.\n",
        "\n",
        "2. The quantizing model in trained with the encoder weights frozen and the quantization and dequantization modules enabled, with the purpose of training the decoder for undoing the quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BvXFvg6JGJEC"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MmoCLvQAGJEG",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 48,\n",
        "    'quantize' : True,\n",
        "    'num_bits' : 3,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 2500,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment3\",\n",
        "    'port' : 6300,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p  share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AFNQeJguGJEV"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OMSkESehGJEY",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wsde2q-qrdt4"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-NLmRyGrduH",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sLqPM4SVGJEo"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3__3I_RGJEq",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7a4-8S2zGJE1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8fTNoEnPGJE3",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rtCg0G_xXOcg"
      },
      "source": [
        "# Experiment 4: sparsity at 1/8\n",
        "\n",
        "At this point it becomes evident that if we want to achieve a compression ratio in the range of 1/10 to 1/20 for comparing with JPEG and JPEG 2000, it is unlikely that using a 1/4 sparsity is bringing us even nearly close, no matter what the accuracy of our image coder is.\n",
        "\n",
        "Although we can certainly try to rely on quantization and entropic coding for bridging the compression ratio gap from 1/4 to 1/10, it seems a bit of a stretch to say the least.\n",
        "\n",
        "It seems that a of 1/8 sparsity on our autoencoder would be a better starting point for the quantization and entropy coding effort to bring close to JPEG. \n",
        "\n",
        "Hence, in this experiment we train a model that reduces dimensionality to 1/8, although but we do not perform quantization. Not introducing quantization yet is compatible with the concept of training in two stages, tried in experiment 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mmSbHULXXOdB"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKJiya2UXOdG",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 110000,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment4\",\n",
        "    'port' : 6400,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b91bYEFdXOdV"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uSDuBz5_XOdX",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U5ScHvWZrkIW"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aG-duT5yrkIZ",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gbgz7eK1XOde"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yXPwaOcCXOdf",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MeAjZle3XOdp"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8K4Tt9ddXOdq",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NcJQhhMHX8cE"
      },
      "source": [
        "#  Experiment 5: 6 bits quantization\n",
        "\n",
        "We do the second stage of training the quantizing model. The second stage of the training is achieved is by transfering the encoder and decoder weights learned with experiment 4, freezing the encoder weights and further training the decoder for undoing the quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K7BbLuRjX8cP"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFgpRLGhX8cX",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-8,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : True,\n",
        "    'num_bits' : 6,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 12650,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment5\",\n",
        "    'port' : 6500,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mDGfpbPiX8cy"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CCmRZr9X8c8",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9PUc0fErgR8"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n2KXO_gprgSL",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HpFrINjjX8dB"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6_0YSBKWX8dC",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6-mgwrlMX8dN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vV5cwb9NX8dP",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n4BQD-rSPtrL"
      },
      "source": [
        "# Experiment 6: blending in more training data\n",
        "\n",
        "In this experiment we try a radically different approach for training the same model from experiment 4. Rather than running for as many epochs as possible (110K in experiment 4) we do fewer epochs with an increased dataset size (60K samples as opposed to 1K samples in experiment 4) and an increased learning rate.\n",
        "\n",
        "The approach really pays off, achieving higher accuracy with just 5 days of training (a opposed to 14 days in experiment 4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z4YU_26MPtrW"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0M7rmdf6Ptrc",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 2e-5,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : False,\n",
        "    'num_bits' : 0,\n",
        "    'train_dataset_size' : 60000,\n",
        "    'test_dataset_size' : 6000,\n",
        "    'num_epochs' : 960,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment6\",\n",
        "    'port' : 6600,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2bUq86RIPtrv"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YkCJsNRGPtrx",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iJR_u2U4Ptr8"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RF9iqNx6Ptr_",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "plzEo7qtPtsE"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUFtgJysPtsF",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QYGh1MhUPtsK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZ3Vph2JPtsL",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s3Wj1F3ERlnw"
      },
      "source": [
        "#  Experiment 7: 6 bits quantization of final model\n",
        "\n",
        "In this  experiment we introduce a 6 bits quantization in the model from experiment 6. For the training we used only 12 additional hours of a Tesla P100.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XQnd9TbYRln6"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tLfBVbWbRloC",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-8,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'quantize' : True,\n",
        "    'num_bits' : 6,\n",
        "    'train_dataset_size' : 60000,\n",
        "    'test_dataset_size' : 6000,\n",
        "    'num_epochs' : 100,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment7\",\n",
        "    'port' : 6700,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VUUR48_LRloZ"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IQcS602ORlob",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.TwitterCompressor(\n",
        "    hidden_state_num_channels=hparams['hidden_state_num_channels'],\n",
        "    quantize=hparams['quantize'],\n",
        "    num_bits=hparams['num_bits'])\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1tnAufY3Rlol"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MMM-WijJRlol",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8oe81ftRRloq"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mMnXZ-fRlor",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "munl0wimRlox"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y-8Ao0iURloy",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nds4uNnRSvn",
        "colab_type": "text"
      },
      "source": [
        "# Results\n",
        "\n",
        "The model from experiment 7 achieves a 10.6 compression ratio with a 43.3 dB PSNR, being the best choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzbSCysjamF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}