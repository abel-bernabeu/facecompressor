{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compressor_train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abel-bernabeu/autoencoder/blob/master/compressor_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myODRbvAf3EK",
        "colab_type": "text"
      },
      "source": [
        "# Compression models training\n",
        "\n",
        "This notebook is used for training the compression models from the autoencoder.models package.\n",
        "\n",
        "It is divided in sections, each of them corresponding to an experiment. In each of those experiments we craft an incrementally functional prototype. A series of five experiments leads to the final model.\n",
        "\n",
        "For each experiment we do:\n",
        "\n",
        "- Specify the hyperparmeters (hparams).\n",
        "- Instantiate a model from the autoencoder.models package.\n",
        "- Create dataloaders with the input patch size and batch size especified in hparams.\n",
        "- Embed a TensorBoard for visualiazing the training.\n",
        "- Kick a training session lasting until the number of epochs especified in hparams is reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiB2DKaId1qC",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Firstly, we download from DropBox the dataset and all the available pre-trained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO6AfnaUoiI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When on Google Colab force PyTorch version to 1.4.0 (for compatibility of the .pt files)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    !pip install torch==1.4.0 torchvision==0.5.0\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Get the dataset if needed\n",
        "import os.path\n",
        "if not os.path.isdir('./data'):\n",
        "    !rm  -rf image_dataset_part-a.zip\n",
        "    !mkdir data -p\n",
        "    !cd data ; wget https://www.dropbox.com/s/91rpg5dqkhhhkzu/image_dataset_part-a.zip\n",
        "    !cd data ; unzip -q image_dataset_part-a.zip && rm image_dataset_part-a.zip \n",
        "\n",
        "# Get the latest source code if needed\n",
        "if not os.path.isdir('./autoencoder'):\n",
        "    !wget https://www.dropbox.com/s/jfu0ksttohnklkq/autoencoder-master.zip && \\\n",
        "    unzip -q autoencoder-master.zip && rm autoencoder-master.zip && \\\n",
        "    mv autoencoder-master/autoencoder/ . && \\\n",
        "    rm autoencoder-master -rf\n",
        "\n",
        "if not os.path.isdir('./share'):\n",
        "    try:\n",
        "        # Try to mount share from Google Drive when on Collab\n",
        "        from google.colab import driveX\n",
        "        drive.mount('/content/drive/')\n",
        "        !ln -s  /content/drive/My\\ Drive/archive/2020/aidl/ share\n",
        "    except:\n",
        "        # The fallback for when not in Collab is to download share from Dropbox\n",
        "        !wget https://www.dropbox.com/s/76w9gsga8mz5ve4/share.tgz && tar xzf share.tgz && rm share.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAJ1smCz1y0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autoencoder.models\n",
        "import autoencoder.utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGvOW4eo2S7Y",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 1: sparsity at 1/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi0IGZoiE-CA",
        "colab_type": "text"
      },
      "source": [
        "Our baseline model effort focuses on training the proposed neural network with the maximum possible accuracy, but not investing any effort in quantization of the features.\n",
        "\n",
        "This model assumes the input is provided in single-precision float values (using 32 bits per pixel color component) and provides a 50% dimensionality reduction of the input (or 1/2 sparsity). The dimensionality reduction is achieved by using 96 channels in the features tensor (as opposed to 192 channels that would be needed if we wanted to keep the dimensionality from the input).\n",
        "\n",
        "The purpose of this first experiment is to:\n",
        "\n",
        "- empirically prove that the input can be reconstructed accurately with the kind of neural network that is proposed in the paper.\n",
        "\n",
        "- set an upper bound on accuracy (which turned out be **43 db**)\n",
        "\n",
        "- give an estimation of how long it takes to train a state of the art compression model (which turned out to take **4 days on a Tesla P100**)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvnxFWQlPiY",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdAi7hZDf3EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 32,\n",
        "    'lr' : 1e-3,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 128,\n",
        "    'block_height' : 128,\n",
        "    'hidden_state_num_channels' : 96,\n",
        "    'train_dataset_size' : 5000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 12577,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment1\",\n",
        "    'port' : 6100,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntf1Z4_Yf3Eg",
        "colab_type": "text"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OKn6N3TbJ84",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(hidden_state_num_channels = hparams['hidden_state_num_channels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c5HCzjKMrL6g"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4A-S3GBUrL6k",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysBd-c-DlYA8",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKr9CMXqSDj2",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cyzSi8YlnvG",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jOW0NNlhfHA5",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UynFM6TYEL12",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 2: sparsity at 1/4\n",
        "\n",
        "In this second experiment we further squeeze the features tensor, going from from 96 channels to only 48, for achieving a 25% dimensionality reduction. Again no quantization is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJEvb7N22tNR",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xBTpKybm2yAp",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 48,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 16000,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment2\",\n",
        "    'port' : 6200,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aE-Rr3v2pdD",
        "colab_type": "text"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW_nmDLzGj0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(hidden_state_num_channels = hparams['hidden_state_num_channels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xpJojH_grVTD"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mtTm5hxPrVTP",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxmt1Lv4wBl",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxUAGmi43tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deyZjDZx5jfa",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCm6ZWG05exL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRgc18irGJDk"
      },
      "source": [
        "#  Experiment 3: 3 bits quantization\n",
        "\n",
        "For this third iteration we introduce 3 bits quantization of the features. We transfer the learned weigths from the previous experiment (a model with the same number of feature channels but no quantization).\n",
        "\n",
        "Then we train the model freezing the encoder, but adjusting the encoder for learning to \"undo\" the quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BvXFvg6JGJEC"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MmoCLvQAGJEG",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 48,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 2500,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment3\",\n",
        "    'port' : 6300,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p  share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AFNQeJguGJEV"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OMSkESehGJEY",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.QuantizingCompressionAutoencoder(num_bits=3)\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wsde2q-qrdt4"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-NLmRyGrduH",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sLqPM4SVGJEo"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3__3I_RGJEq",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7a4-8S2zGJE1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8fTNoEnPGJE3",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxcAT8eV6KGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rtCg0G_xXOcg"
      },
      "source": [
        "# Experiment 4: sparsity at 1/8\n",
        "\n",
        "In this experiment we reduce dimensionality to 1/8, but we do not perform quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mmSbHULXXOdB"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKJiya2UXOdG",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 110000,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment4\",\n",
        "    'port' : 6400,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b91bYEFdXOdV"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uSDuBz5_XOdX",
        "colab": {}
      },
      "source": [
        "model = autoencoder.models.TwitterCompressor(hidden_state_num_channels = hparams['hidden_state_num_channels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U5ScHvWZrkIW"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aG-duT5yrkIZ",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gbgz7eK1XOde"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yXPwaOcCXOdf",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MeAjZle3XOdp"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8K4Tt9ddXOdq",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NcJQhhMHX8cE"
      },
      "source": [
        "#  Experiment 5: 6 bits quantization\n",
        "\n",
        "We transfer the learned encoder and decoder from experiment 4, freeze the encoder weights and further train the decoder for undoing the quantization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K7BbLuRjX8cP"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFgpRLGhX8cX",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-10,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 24,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 20000,\n",
        "    'num_workers' : 4,\n",
        "    'name' : \"experiment5\",\n",
        "    'port' : 6500,\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 200,\n",
        "}\n",
        "\n",
        "!mkdir -p share/{hparams['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mDGfpbPiX8cy"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CCmRZr9X8c8",
        "colab": {}
      },
      "source": [
        "qmodel = autoencoder.models.QuantizingCompressionAutoencoder(num_bits=6)\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9PUc0fErgR8"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n2KXO_gprgSL",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HpFrINjjX8dB"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6_0YSBKWX8dC",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # When on Google Colab try to launch an embedded TensorBoard\n",
        "    from google.colab import drive\n",
        "    %load_ext tensorboard\n",
        "    from tensorboard import notebook\n",
        "    notebook.start('--logdir share/' + hparams['name'] + '/runs/ --port ' + str(hparams['port']))\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6-mgwrlMX8dN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vV5cwb9NX8dP",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DurFdBHzCF2",
        "colab_type": "text"
      },
      "source": [
        "# Results\n",
        "\n",
        "The model from experiment 5 achieves a 10.6 compression ratio with a 39.1 dB PSNR, being the best choice."
      ]
    }
  ]
}